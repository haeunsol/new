{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0688c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = pd.read_csv('resample_10.csv')\n",
    "df_11 = pd.read_csv('resample_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_10, df_11]) \n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f732470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['time'] = pd.to_datetime(df_new['time'])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tick_to_ohlcv(data):\n",
    "    \"\"\"\n",
    "    Converts given Binance tick data into 1-hour interval OHLCV (Open, High, Low, Close, Volume) data.\n",
    "    :param data: DataFrame with Tick data\n",
    "    :return: DataFrame with the Open, High, Low, Close, Volume values\n",
    "    \"\"\"\n",
    "    ohlcv = data.resample('1T',on='time').agg({\n",
    "        'price': ['first', 'max', 'min', 'last'],\n",
    "        'qty': 'sum'\n",
    "})\n",
    "\n",
    "    ohlcv.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    return ohlcv\n",
    "\n",
    "def calculate_volatility(data, window=20):\n",
    "    \"\"\"\n",
    "    Calculate the rolling volatility using the standard deviation of returns.\n",
    "    :param data: DataFrame with OHLCV data\n",
    "    :param window: The number of periods to use for calculating the standard deviation\n",
    "    :return: DataFrame with the volatility values\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate daily returns\n",
    "    data['returns'] = data['Close'].pct_change()\n",
    "\n",
    "    # Calculate the rolling standard deviation of returns\n",
    "    data['volatility'] = data['returns'].rolling(window=window).std()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387abbe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ohlcv=convert_tick_to_ohlcv(df_new)\n",
    "ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=calculate_volatility(ohlcv, window=20)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0fadf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=result[['volatility']]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03599969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=a.reset_index()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae848391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de674e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b=pd.merge(df_new,a,on='time')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b=b.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf50745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b=b.iloc[21:]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(b.volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outlier(value):\n",
    "    Q1 = b['volatility'].quantile(0.25)\n",
    "    Q3 = b['volatility'].quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "    rev_range = 3\n",
    "\n",
    "    if((value <(Q1-rev_range*IQR))):\n",
    "        value = np.nan\n",
    "    if((value >(Q3+rev_range*IQR))):\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b518a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['volatility'] = b['volatility'].apply(replace_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99551661",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=b.dropna()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result.drop('volatility',axis=1) # 변동성 빼고 나머지 데이터 프레임\n",
    "y = result['volatility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dafd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor 모델과 mape 기준으로 튜닝할 하이퍼파라미터 그리드 정의\n",
    "\n",
    "# MAPE를 계산하는 함수 정의\n",
    "def mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    MAPE 계산 함수\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: 실제값의 배열\n",
    "    - y_pred: 예측값의 배열\n",
    "\n",
    "    Returns:\n",
    "    - mape: MAPE 값\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    # 0으로 나누는 것을 방지하기 위해 실제값이 0인 경우는 0으로 대체\n",
    "    mask = y_true != 0\n",
    "    y_true, y_pred = y_true[mask], y_pred[mask]\n",
    "\n",
    "    # MAPE 계산\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    return mape\n",
    "\n",
    "# MAPE를 사용자 정의 스코어로 등록\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "# RandomForestRegressor 모델과 튜닝할 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 15, 20]\n",
    "}\n",
    "\n",
    "# 모델 생성\n",
    "rf_model = RandomForestRegressor(random_state=111)\n",
    "\n",
    "# GridSearchCV 생성\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring=mape_scorer)\n",
    "\n",
    "# 데이터에 모델을 적합시키고 최적의 하이퍼파라미터를 찾음\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72cad0",
   "metadata": {},
   "source": [
    "* 거의 1시간 넘게 안 돌아간 듯 코랩에서 gqu 써서 해봐야겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=20,random_state=111)\n",
    "rf_model.fit(X_train, y_train) # 모델 학습\n",
    "\n",
    "# 학습된 모델을 사용하여 테스트 데이터 예측\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "r2score = r2_score(y_true = y_test, y_pred =y_pred) ## R-squared score\n",
    "mse = mean_squared_error(y_true = y_test, y_pred =y_pred) ## MSE (Mean Squared Error)\n",
    "mae = mean_absolute_error(y_true = y_test, y_pred =y_pred) ## MAE (Mean Absolute Error)\n",
    "mape=mean_absolute_percentage_error(y_true=y_test, y_pred=y_pred) ## MAPE\n",
    "\n",
    "print(\"r2score :\", r2score)\n",
    "print(\"mse :\", mse)\n",
    "print(\"mae :\", mae)\n",
    "print(\"mape :\", mape) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
